\documentclass[fontsize=12pt, DIV=12]{scrreprt}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}

% Setting up referencing
\usepackage[backend=biber]{biblatex}
\addbibresource{references.bib}

% Setting up theorem, claim, proof, etc. environments
\usepackage{thmtools}
\usepackage{thm-restate}

\usepackage{varioref}
\usepackage[hidelinks]{hyperref}
\usepackage{cleveref}

\usepackage{mdframed}

\declaretheorem[name=Definition, numberwithin=chapter, thmbox=L]{defn}
\declaretheorem[name=Theorem, thmbox=L, sibling=defn]{theorem}
\declaretheorem[name=Lemma, thmbox=L]{lemma}
\declaretheorem[
	name=Proposition,
	refname={proposition, propositions},
	Refname={Proposition, Propositions},
	thmbox=L,
	sibling=defn]{prop}
\declaretheorem[name=Corollary, thmbox=L, sibling=defn]{corollary}
\declaretheorem[name=Remark, thmbox=S, sibling=defn]{remark}

\usepackage{amsthm}

\newtheorem{claim}{Claim}

\newenvironment{subproof}[1][\proofname]{%
  \renewcommand{\qedsymbol}{$\blacksquare$}%
  \begin{proof}[#1]%
}{%
  \end{proof}%
}

\newcommand{\defeq}{\coloneqq}
\newcommand{\op}{\text{op}}
\let\C\relax
\newcommand{\R}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\E}{\mathbb E}
\newcommand{\N}{\mathbb N}
\newcommand{\Q}{\mathbb Q}
\newcommand{\prob}{\mathbb P}
\newcommand{\indi}{\mathbb 1}
\newcommand{\calA}{\mathcal A}
\newcommand{\calB}{\mathcal B}
\newcommand{\calD}{\mathcal D}
\newcommand{\calE}{\mathcal E}
\newcommand{\calF}{\mathcal F}
\newcommand{\calH}{\mathcal H}
\newcommand{\calT}{\mathcal T}
\newcommand{\calL}{\mathcal L}
\newcommand{\calR}{\mathcal R}
\newcommand{\dif}[1]{\text{d} #1}
\newcommand{\towk}{\Rightarrow}
\DeclareMathOperator{\reg}{Reg}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\cov}{Cov}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\cyl}{Cyl}
\DeclareMathOperator{\tr}{Tr}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\ev}{ev}
\DeclareMathOperator{\eq}{eq}
\DeclarePairedDelimiterX{\abs}[1]{\lvert}{\rvert}{#1}
\DeclarePairedDelimiterX{\norm}[1]{\lVert}{\rVert}{#1}
\DeclarePairedDelimiterX{\inn}[2]{\langle}{\rangle}{#1, #2}
\newcommand{\boxspace}{\ensuremath{\R^{[0, 1]^d}}}
\newcommand{\unitbox}{\ensuremath{[0,1]^d}}
\renewcommand{\phi}{\varphi}
\newcommand{\simiid}{\overset{\text{i.i.d.}}{\sim}}
\newcommand{\mudif}{\ensuremath{\, \mu(\dif x)}}

\usepackage{tikz-cd}

\title{Stochastic Partial Differential Equations}
\author{Based on Lectures by Dr. A. Chandra and Dr. G. Cannizzaro}

\begin{document}

\maketitle

\tableofcontents

\chapter{Gaussian Measure Theory}

\section{Introduction}

The driving motivation throughout this chapter is defining a Banach space valued Wiener process and defining how to integrate against it. Recall a $\R^n$-valued stochastic process $(W_t)_{t \geq 0}$ is a Wiener process if and only if it is a continuous Gaussian process with mean 0 and covariance function $C(s, t) = (s \wedge t) I$ where $I$ is the $d \times d$ identity matrix. This is a nice short definition, and it's easy to take for granted the amount of measure theory it took to get to this definition. Let's spell some of those steps out.
\begin{enumerate}
	\item We developed tools like mean, covariance and Fourier transforms to analysis real random variables.
	\item We defined what a Gaussian random variable was and used our tools to analyse their properties.
	\item We showed existence of a Gaussian process with the correct covariance structure.
	\item We proved a continuity criterion showing our Gaussian process has a continuous modification.
\end{enumerate}
For a Banach space $\calB$-valued stochastic process, we currently have none of these tools. The goal of this chapter is to remedy that.

\section{Analysis of Banach-valued random variables}

\subsection{Two approaches}

Throughout these notes $\calB$ be a real Banach space. Usually $\calB$ will also be seperable, but we'll try and say explicitly when this is the case. Let $\mu$ be a Borel probability measure on $\calB$ and $X$ be a $\calB$-valued random variable such that $X \sim \mu$. We'd like recover tools like means and Fourier transforms. Let's start with the mean, say $m$. From the finite dimensional case it's tempting to define
\begin{equation}
	m \defeq \int_{\calB} x \, \mu(\dif x).
\end{equation}
However this integral cannot be understand as a Lebesgue integral. After all, $x$ doesn't take values in $\R^n$. At this point we have two options.

\subsubsection{Option one: the Bochner integral}

We could try and rigorously define this integral. The method of integration used for $\calB$-valued functions are Bochner integrals. The construction of the Bochner integral follows the same method as the Lebesgue integral; we define the integral for a class of simple functions and extend the integral by approximation. Rather than going into details on the construction, we'll list off some of the properties of the Bochner integral. Firstly let $(E, \calE, \nu)$ be a probability space and $f: E \to \calB$ be measurable and $\calB$ be seperable\footnote{Seperability of $\calB$ is need to ensure $f$ is the pointwise limit of simple functions, i.e.\ strong measurablity. If we take strong measurability as an additional assumption on $f$ then seperability of $\calB$ can be relaxed}. Then $f$ is integrable if and only if

\begin{equation}
	\int_E \norm{f(x)}_E \, \nu(\dif x) < \infty.
\end{equation}
The Bochner integral behaves nicely with bounded linear operators. Let $\hat{\calB}$ be another Banach space and $L: \calB \to \hat{\calB}$ be a bounded linear operator. Then the Bochner integral can be exchanged with $L$, i.e.\ for all integrable $f: E \to \calB$,
\begin{equation}
	\int_E L(f(x)) \, \nu(\dif x) = L\left( \int_E f(x) \, \nu(\dif x)\right).
\end{equation}
Hence if we assume $\int_E \norm{x} \, \mu(\dif x) < \infty$ then the mean
\begin{equation}
	\bar{m}_{\mu} \defeq \int_E x \, \mu(\dif x)
\end{equation}
can be defined using the Bochner integral. This approach is valuable in how it carrys the intuition from the finite dimensional case. In addition, it makes clear that the mean is an element of $\calB$ without the use of reflexivity (as we will see in the next approach). 

\subsubsection{Option two: one-dimensional marginals}

Alternatively, we've already developed a rich theory of Lebesgue integration for $\R$-valued functions. What if we instead used this theory? This would require a `natural' way to map $\calB$ to $\R$. Since $\calB$ is a normed vector space, we have exactly that: the space of bounded linear functionals $\calB^*$. For any $l \in \calB^*$, $\E[l(X)]$ is just given by a Lebesgue integral. So to define the mean, just gather all these values for diffent $l \in \calB^*$. Following this idea, we define the mean as $m: \calB^* \to \R$ where
\begin{equation}
	m(l) \defeq \E[l(X)] = \int_{\calB} l(x) \, \mu(\dif x).
\end{equation}
How can we recover a mean $\bar{m}_{\mu} \in \calB$? Suppose that $\int_E \norm{x} \, \mu(\dif x) < \infty$. We can then prove that $m_{\mu}: \calB^* \to \R$ is a bounded linear functional, in other words $m_{\mu} \in \calB^{**}$. At this point we could assume that $\calB$ were reflexive. Then we are guaranteed there exists $\bar{m}_{\mu} \in \calB$ such that
\begin{equation}
	m_{\mu}(l) = l(\bar{m}_{\mu}) \quad \forall l \in \calB^*.
\end{equation}
However, this is unnecessary supposing $\calB$ is seperable. From our first approach of using Bochner integrals, we know in fact that $\int_{\mu} \norm{x} \, \mu(\dif x) < \infty$ is a sufficient condition to define $\bar{m}_{\mu}$ as in. Then since the Bochner integral can be exchanged with any $l \in \calB^*$, the property in holds. This shows two things. Firstly, it shows our two approaches recover the same mean. Secondly, it shows reflexivity is an extraneous assumption.

The value of this second approach really shines when the concept we're describing becomes more intangible than a mean, in particular later when we define a Gaussian measure on $\calB$

\subsection{Marginals characterise measures}

Seen as we're working with $l(X)$ so much, it's useful to have a notation for its law.
\begin{defn}[Pushforward measures]
	Let $(E, \calE)$ and $(F, \calF)$ be measurable spaces. Let $\mu$ be a measure on $(E, \calE)$ and $f: (E, \calE) \to (F, \calF)$ be measurable. Then the \emph{pushforward} of $\mu$ be $f$ is the measure $f_* \mu$ on $(F, \calF)$ where
	\begin{equation}
		f_* \mu(A) \defeq \mu(f^{-1}(A)).
	\end{equation}
\end{defn}

This is defined so that $l(X) \sim l_* \mu$. It is also sensible to have a name for the laws $\{l_* \mu : l \in \calB^*\}$.
\begin{defn}[One-dimensional marginals]
	Let $\mu$ be a probability measure on $\calB$. Then the \emph{one-dimenional margins} of $\mu$ are the laws $l_* \mu$ for all $l \in \calB^*$.
\end{defn}

The next proposition shows that the one-dimensional marginals carry enough information to uniquely characterise a meaure $\mu$.
\begin{prop}[Sufficiency of one-dimensional marginals]
	\label{prop:one-dim-marginals}
	Let $\mu$ and $\nu$ be Borel probability measures on a seperable Banach space $\calB$. Suppose $l_* \mu = l_* \nu$ for all $l \in \calB^*$. Then $\mu = \nu$.
\end{prop}
\begin{proof}
	We start in finite dimensions, suppose $\calB = \R^n$. Then considering Fourier transforms. All $\xi \in \R^n$ defines a bounded linear functional $l_{\xi}: \R^n \to \R^n$ by $l_{\xi}(x) = \xi \cdot x$. Therefore
	\begin{align}
		\hat{\mu}(\xi)
		&= \int_{\R^n} e^{i \xi \cdot x} \mu(\dif x)
		= \int_{\R} e^{i t} \, (l_{\xi})_*\mu(\dif t) \\
		&= \int_{\R} e^{i t} \, (l_{\xi})_*\nu(\dif t)
		= \hat{\nu}(\xi).
	\end{align}
	Since Fourier transforms uniquely determine probability measures, $\mu = \nu$.
	
	For infinite dimensions, the cylindrical sets of $\calB$ are given by
	\begin{equation}
		\cyl(\calB) \defeq \{T^{-1}(A) : T: \calB \to \R\ \text{linear and bounded},\ A \subset \R^n\ \text{Borel}\}.
	\end{equation}
	This is a subset of the Borel $\sigma$-algebra on $\calB$ by continuity of $\calB$. This is a $\pi$-system since 
	\begin{equation}
		T^{-1}(A) \cap S^{-1}(B) = (T \oplus S)^{-1}(A \times B).
	\end{equation}
	By the finite dimensional case we just proved, $T_* \mu$ is uniquely determined by
	\begin{equation}
		\{L_*(T_* \mu) : L \in (\R^n)^* \} = \{ (L \circ T)_* \mu : L \in (\R^n)^* \}
		\subset \{l_* \mu : l \in \calB^*\}.
	\end{equation}
	Thus $\mu$ and $\nu$ agree on $\cyl(\calB)$ and therefore $\sigma(\cyl(\calB))$. The topology on any seperable metric space is generated by countable unions of balls, thus it suffices to show $B_r(x_0) \in \cyl(\calB))$ for any $x_0 \in \calB$, $r > 0$. There exists linear functionals $l_n \in \calB^*$ such that 
	\begin{equation}
		\norm{x} = \sup_n l_n(x).
	\end{equation}
	Thus
	\begin{align}
		B_r(x_0) = \bigcap_n \{x \in \calB : l_n(x - x_0) \leq r \} \in \cyl(\calB).
	\end{align}
\end{proof}

\subsection{Mean and covariance}

We formalise what we said in the introduction.

\begin{defn}[Mean Operator]
	Let $\mu$ be a probability measure on $\calB$ and suppose $l_* \mu$ has finite mean for all $l \in \calB^*$. Then the \emph{mean operator} of $\mu$ is a linear operator $\mu: \calB^* \to \R$ where
	\begin{equation}
		m_{\mu}(l) \defeq \int_{\cal B} l(x) \, \mu(\dif x).
	\end{equation}
	$\mu$ is \emph{centered} if $m_{\mu} \equiv 0$.
\end{defn}

Similarly we can define the covariance.

\begin{defn}[Covariance Operator]
	Let $\mu$ be a probability measure on $\calB$ and suppose $l_* \mu$ has finite second moment for all $l \in \calB^*$. Then the \emph{covariance operator} of $\mu$ is the bilinear operator $C_{\mu} : \calB^* \times \calB^* \to \R$ where
	\begin{equation}
		C_{\mu}(l, l') \defeq \int_{\calB} l(x) l'(x) \mu(\dif x).
	\end{equation}
\end{defn}
\begin{remark}
	Note that $C_{\mu}$ is a symmetric, positive semi-definite, bilinear operator.
\end{remark}

We'll leave the question of whether or not these operators are bounded till later.

\subsection{Fourier transforms}

\begin{defn}[Fourier Transform]
	The \emph{Fourier transform} of a probabilty measure $\mu$ on $\calB$ is given by $\hat{\mu} \in \calB^* \to \C$ where
	\begin{equation}
		\hat{\mu}(l) = \int_{\calB} e^{i l(x)} \mu(\dif x).
	\end{equation}
\end{defn}
\begin{remark}
	Unlike the mean, the Fourier transform of a measure of $\R^n$ is normally a function to begin with, just a function $\R^n \to \R$ rather than $(\R^n)^* \to \R$. This is a use of the Hilbert space structure on $\R^n$. For a general Hilbert space $\cal H$, let $\mu$ be a probabilty measure on $\calH$. We can then instead define $\hat{\mu}: \calH \to \R$ by
	\begin{equation}
		\hat{\mu}(\xi) \defeq \int_{\calH} e^{i \inn{\xi}{x}} \mu(\dif x).
	\end{equation}
	This is then equivalent to our definition since by the Riesz representation theorem the map $\xi \to l_{\xi}$ where $l_{\xi}(x) = \inn{\xi}{x}$ is an isomorphism between $\calH$ and $(\calH)^*$.
\end{remark}

In the finite dimensional case, Fourier transforms uniquely determine distributions. This holds true in seperable Banach spaces.
\begin{prop}[Uniqueness of Fourier transforms]
	Let $\mu$ and $\nu$ be probability measures on a seperable Banach space $\calB$. If $\hat{\mu} = \hat{\nu}$ then $\mu = \nu$.
\end{prop}
\begin{proof}
	$\hat{\mu}$ uniquely determines the (classical) Fourier transform of $l_* \mu$ since
	\begin{equation}
		\widehat{l_* \mu}(\xi) = \hat{\mu}(\xi l).
	\end{equation}
	From the finite dimensional case we know $\widehat{l_* \mu}$ uniquely determines $l_* \mu$. Therefore $\hat{\mu}$ uniquely determines the one-dimensional marginals of $\mu$, and thus $\mu$ itself by \vref{prop:one-dim-marginals}.
\end{proof}

\section{Gaussian measures}

We've now got our tools ready. Now we'll move onto the next step, defining what a Gaussian random variable is.

\subsection{Basic definition and mean-covariance characterisation}

As aluded to in the section on analysis of $\calB$-valued random variables, there is not an immediately obvious definition for what a Gaussian measure is on $\calB$ using Bochner integrals. We can't really hope for a density function after all, there's no generalisation of the Lebesgue measure to general Banach spaces. However we do know what Gaussian measures are on $\R$, so we can use our approach of considering one-dimensional marginals.
\begin{defn}[Gaussian measures]
	A Borel probability measure $\mu$ on $\calB$ is a \emph{Gaussian measure} if $l_* \mu$ is a Gaussian measure. Note we consider Dirac measures to be variance 0 Gaussian measures in this definition.
\end{defn}

Gaussian measures on $\R^n$ are uniquely characterised by their covariance and mean. This is true since they uniquely determine the Fourier transform. This remains true in infinite dimensions.
\begin{prop}[Fourier transform of Gaussian measures]
	Let $\mu$ be a Gaussian measure on $\calB$. Then
	\begin{equation}
		\hat{\mu}(l) = \exp\left\{i m_{\mu}(l) - \frac{1}{2} C_{\mu}(l, l) \right\}.
	\end{equation}
\end{prop}
\begin{corollary}[Mean and cov.\ uniquely characterise Gaussian measures]
	A Gaussian measure on a seperable Banach space is uniquely determined by it's mean and covariance operators.
\end{corollary}

\subsection{Integrability of Gaussian measures}

It's hopefully somewhat intuitive that boundedness of the covariance operator will be related to boundedness of the second moment of the corresponding measure. In finite dimensions, Gaussian random variables are nice because of the rapid tail decay of the probability density function. We now show a similar statement is true for general Gaussian measures. Suprisingly, this will come from rotational invariance of Gaussian measure. 

\begin{defn}[Rotational invariance]
	Let $\mu$ be a measure on $\calB$. For each $\phi \in \R$, define $R_{\phi}: \calB \times \calB \to \calB \times \calB$ by
	\begin{equation}
		R_{\phi}(x, y) = (x \sin \phi + y \cos \phi, x \cos \phi - y \sin \phi).
	\end{equation}
	Then $\mu$ is \emph{invariant under rotations of $\phi$} if $(R_{\phi})_* (\mu \otimes \mu) = \mu \otimes \mu$.
\end{defn}

\begin{prop}[Rotational invariance of centered Gaussians]
	Centered Gaussian measures on a seperable Banach space $\calB$ are invariant under rotations by any angle.
\end{prop}
\begin{proof}
	Check the Fourier transform of the rotated measure is equal to the fourier transform of the original measure.
\end{proof}

The following theorem shows as long as a measure is invariance under rotations of $\frac{\pi}{4}$ then it has double exponential tail decay.
\begin{theorem}[Fernique]
	Let $\mu$ a probability measure on $\calB$. Suppose $\mu$ is invariant under rotations by $\frac{\pi}{4}$. Then there exists $\alpha > 0$ such that $\norm{x}$ has doubly exponential moments, i.e.\
	\begin{equation}
		\int e^{\alpha \norm{x}^2} \, \mu(\dif x) < \infty.
	\end{equation}
\end{theorem}
\begin{proof}
	Take $t, \tau > 0$. Then
	\begin{align}
		\mu(\norm{x} \leq \tau) \mu(\norm{x} > t)
		&= \mu \otimes \mu\left( \frac{\norm{x + y}}{\sqrt{2}} > t, \frac{\norm{x+y}}{\sqrt{2}} > \tau \right) \\
		&\leq \mu \otimes \mu \left(\norm{x} > \frac{t - \tau}{2}, \norm{x} > \frac{t - \tau}{2}) \right) \\
		&= \mu\left(\norm{x} > \frac{t - \tau}{2}\right)^2
	\end{align}

	INSERT REST OF PROOF
\end{proof}

Fernique's theorem allows us to not only show all moments of a Gaussian measure are finite, it allows us to bound the higher moments using the first moment.

\begin{prop}[Moment bounds on Gaussians]
	\label{prop:bounded-moments}
	Let $\mu$ be a centered Gaussian on $\calB$. Then there exists $\alpha, K > 0$ such that for all $n \in \N$
	\begin{equation}
		\int_{\calB} \abs{x}^{2n} \, \mu(\dif x) \leq n! K \alpha^{-n} M^{2n}.
	\end{equation}
	where $M = \int_{\calB} \norm{x} \, \mu(\dif x)$.
\end{prop}
\begin{proof}
	INSERT PROOF
\end{proof}

\section{Existence of Gaussian Measures}

Existence of Gaussian measures is hard. First let us recall the method in finite dimensions. Given any symmetric, positive semi-definite matrix $\Sigma$ it is possible to compute its Cholesky factorisation $L$ such that $\Sigma = LL^T$. Then by taking product measures we can construct a standard Gaussian $X \sim N(0, I)$. Then $LX \sim N(0, \Sigma)$.

This section is our first foray into existence results. All our Gaussians will be centered so we just need to worry about the covariance operator. In finite dimensions, we know covariance matrices must be symmetric and positive semi-definite. The first thing we show is that boundedness is required as well when working in infinite dimensions.

\begin{prop}[Boundedness of covariance operators]
	\label{prop:bounded-cov}
	Let $\mu$ be a centered Gaussian measure on a seperable Banach space. Then there exists $\norm{C_{\mu}} < \infty$ such that $C_{\mu}(l, l') \leq \norm{C_{\mu}} \norm{l} \norm{l'}$. Moreover there exists continuous operator $\hat{C}_{\mu}: \calB^* \to \calB$ such that
	\begin{equation}
		C_{\mu}(l, l') = l'\left(C_{\mu}(l) \right).
	\end{equation}
\end{prop}
\begin{proof}
	The first part of the proof is clear by setting $\norm{C_{\mu}}$ to $\int_{\calB} \norm{x}^2 \, \mu(\dif x)$ and employing boundedness of $l$ and $l'$.

	For the second part, since
	\begin{equation}
		\int_{\calB} \norm{x l(x)} \, \mu(\dif x) \leq \norm{l} \int_{\calB} \norm{x}^2 \dif x < \infty
	\end{equation}
	we can formalise
	\begin{equation}
		\hat{C}_{\mu}(l) = \int_{\calB} x l(x) \, \mu(\dif x)
	\end{equation}
	as a Bochner integral. Then since the Bochner integral can be exchanged with continuous linear functionals
	\begin{align}
		l'(\hat{C}_{\mu}(l))
		&= l' \left( \int_{\calB} x l(x) \, \mu(\dif x)\right)
		= \int_{\calB} l'(x l(x)) \, \mu(\dif x) \nonumber \\
		&= \int_{\calB} l(x) l'(x) \mu(\dif x)
		= C_{\mu}(l, l')
	\end{align}
	as required.
\end{proof}

So now let's add boundedness to our list of assumptions. Is that enough to characterize covariance operators of Gaussian measures? Unfortunately the answer is still no. In fact for a general Banach space there is no nice characterisation. However for Hilbert spaces we can give an actual answer.
As promised, we now characterise the covariance operators of Gaussian measures in Hilbert spaces. In \vref{prop:bounded-cov} we've already shown there exists $\hat{C}_{\mu}: \calH^* \to \calH$ such that $C_{\mu}(l, l') = l'(\hat{C}_{\mu}(l))$ for all $l, l' \in \calB^*$. Then by the Riesz representation, there exists $\tilde{C}_{\mu}: \calH \to \calH$ such that
\begin{equation}
	C_{\mu}(\inn{\cdot}{x}, \inn{\cdot}{y}) = \inn{\tilde{C}_{\mu}x}{y}
\end{equation}
We will state our characterisation in terms of $\tilde{C}_{\mu}$. Firstly let's recall some definitions from functional analysis.
\begin{defn}[Positive definiteness and trace-class]
	Let $\calH$ be a seperable Hilbert space and let $L: \calH \to \calH$ be linear.
	\begin{enumerate}
		\item $L$ is \emph{positive definite} if $L$ is self-adjoint (symmetric) and $\inn{L h}{h} > 0$ for all non-zero $h \in \calH$
		\item $L$ is \emph{trace-class} if for any orthonormal basis $(e_n)$ of $\calH$ there exists a sequence of numbers $\{\lambda_n\}$ such that $\sum_n \abs{\lambda_n} < \infty$ and
			\begin{equation}
				\inn{x}{Lx} = \sum_n \lambda_n \inn{x}{e_n}^2.
			\end{equation}
			The \emph{trace} of $L$ is then $\tr L \defeq \sum_n \lambda _n$.
	\end{enumerate}
\end{defn}
You can prove it is sufficient to check the trace-class property for any single orthonormal basis in order for it to hold for all orthonormal bases.

Trace-class is a stronger property than boundedness, in particular there exists operators that are bounded and not trace class. Hence we see symmetry, positive semi-definitess, and boundedess was truly insufficient to characterize Gaussian covariances.
\begin{prop}[Characterisation of Gaussian covariances in Hilbert Spaces]
	Let $\calH$ be a seperable Hilbert space and $\tilde{C}: \calH \to \calH$. Then the following are equivalent
	\begin{enumerate}
		\item There exists a Gaussian measure $\mu$ on $\calH$ such that
			\begin{equation}
				C_{\mu}(\inn{\cdot}{x}, \inn{\cdot}{y}) = \inn{\tilde{C} x}{y} \quad \forall x, y \in \calH.
			\end{equation}
		\item $\tilde{C}$ is a linear operator that is positive semi-definite and trace-class.
	\end{enumerate}
\end{prop}
\begin{proof}
	$(1) \implies (2)$: Bilinerity, symmetry and positive semi-definiteness of $\hat{C}_{\mu}$ translates to linearity, self-adjointness and positive semi-definiteness of $\tilde{C}$ respectively. To show trace-class fix any orthonormal basis $\{e_n\}$. Then
	\begin{align}
		\tr(\tilde{C})
		&= \sum_n \inn{\tilde{C}e_n}{e_n}
		= \sum_n C_{\mu}(\inn{\cdot}{e_n}, \inn{\cdot}{e_n})
		= \sum_n \int_{\calH} \inn{x}{e_n}^2 \, \mu(\dif x) \nonumber \\
		&= \int_{\calH} \sum_n \inn{x}{e_n}^2 \, \mu(\dif x)
		= \int_{\calH} \norm{x}^2 \, \mu(\dif x) < \infty
	\end{align}
	using \vref{prop:bounded-moments}.

	$(2) \implies (1)$: Trace-class operators are compact. The spectral theorem for compact, self-adjoint operators says there is an orthonormal basis $\{e_n\}$ of $\calH$ consisting of eigenvectors of $\tilde{C}$, say $\tilde{C}(e_n) = \lambda _n e_n$, and that the $\lambda_n$ are real. Furthermore $\lambda_n \geq 0$ for all $n$ as $\tilde{C}$ is positive semi-definite. In addition
	\begin{equation}
		\sum_n \lambda_n = \sum_n \inn{\tilde{C} e_n}{e_n} = \tr(\tilde{C}) < \infty.
	\end{equation}
	There exists a probability space on which we can define $X_1, X_2, \ldots$ a sequence of i.i.d.\ $N(0, 1)$ random variables. Then let $\mu_n$ be the law of $\sum_{i=1}^n \sqrt{\lambda_i} X_i e_i$. We can show $\mu_n$ converges weakly to a limit $\mu$ and that $\mu$ is a Gaussian measure with the required covariance.
\end{proof}

\subsection{Cameron-Martin theory}

\appendix

\input{misc-theorems.tex}

\printbibliography

\end{document}
